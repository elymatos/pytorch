{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1891a4b-3bd8-46e4-bf61-5490a074084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Relation Prediction with R-GAT and BERT Embeddings (PyTorch Geometric)\n",
    "\n",
    "# --- Step 0: Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Load Words and Relations from Files ---\n",
    "words_file = 'words.txt'  # one word per line\n",
    "relations_file = 'relations.csv'  # csv with columns: head, relation, tail\n",
    "\n",
    "with open(words_file, 'r') as f:\n",
    "    words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "relations_df = pd.read_csv(relations_file)\n",
    "relations = list(relations_df.itertuples(index=False, name=None))\n",
    "\n",
    "# --- Step 2: Encode Words using XLM-R ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_word_embedding(word):\n",
    "    input_ids = tokenizer.encode(word, return_tensors=\"pt\")\n",
    "    outputs = model(input_ids)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze(0)\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "embeddings = torch.stack([get_word_embedding(w) for w in words])\n",
    "\n",
    "# --- Step 3: Build PyG Graph ---\n",
    "edge_index = []\n",
    "edge_type = []\n",
    "\n",
    "rel_encoder = LabelEncoder()\n",
    "rel_encoder.fit([r[1] for r in relations])\n",
    "\n",
    "for src, rel, dst in relations:\n",
    "    i, j = word2idx[src], word2idx[dst]\n",
    "    edge_index.append([i, j])\n",
    "    edge_type.append(rel_encoder.transform([rel])[0])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "\n",
    "# --- Step 4: Define Improved R-GAT Model with Dropout and LayerNorm ---\n",
    "class RGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_rels, dropout=0.2, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "        self.num_layers = num_layers\n",
    "        self.gats = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                GATConv(in_dim if l == 0 else hidden_dim, hidden_dim, heads=1, concat=False)\n",
    "                for _ in range(num_rels)\n",
    "            ]) for l in range(num_layers)\n",
    "        ])\n",
    "        self.out_proj = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        for layer in self.gats:\n",
    "            out = torch.zeros(x.size(0), layer[0].out_channels, device=x.device)\n",
    "            for rel_id, conv in enumerate(layer):\n",
    "                mask = edge_type == rel_id\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "                rel_edges = edge_index[:, mask]\n",
    "                out += conv(x, rel_edges)\n",
    "            x = self.ln(self.dropout(F.relu(out)))\n",
    "        return self.out_proj(x)\n",
    "\n",
    "# --- Step 5: Edge Classifier with Negative Class ---\n",
    "class EdgeClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(2 * in_dim, num_classes)\n",
    "\n",
    "    def forward(self, src, dst):\n",
    "        x = torch.cat([src, dst], dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# --- Step 8: Evaluation on Test Set ---\n",
    "def evaluate(encoder, classifier, embeddings, edge_index, edge_type, test_pos, num_rels):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        h = encoder(embeddings, edge_index, edge_type)\n",
    "\n",
    "        # Positive test edges\n",
    "        src, dst, labels = test_pos\n",
    "        pos_logits = classifier(h[src], h[dst])\n",
    "        pos_preds = pos_logits.argmax(dim=1)\n",
    "\n",
    "        # Negative test edges\n",
    "        neg_pairs = generate_negative_edges(len(src), len(words), set(zip(src.tolist(), dst.tolist())))\n",
    "        neg_src, neg_dst = zip(*neg_pairs)\n",
    "        neg_src, neg_dst = torch.tensor(neg_src), torch.tensor(neg_dst)\n",
    "        neg_labels = torch.full_like(neg_src, fill_value=num_rels)\n",
    "        neg_logits = classifier(h[neg_src], h[neg_dst])\n",
    "        neg_preds = neg_logits.argmax(dim=1)\n",
    "\n",
    "        # Combine\n",
    "        all_preds = torch.cat([pos_preds, neg_preds])\n",
    "        all_true = torch.cat([labels, neg_labels])\n",
    "\n",
    "        print(classification_report(\n",
    "    all_true.cpu(),\n",
    "    all_preds.cpu(),\n",
    "    labels=list(range(num_rels + 1)),\n",
    "    target_names=list(rel_encoder.classes_) + ['no-relation']\n",
    "))\n",
    "import random\n",
    "\n",
    "def generate_negative_edges(num_neg, vocab_size, existing_set):\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < num_neg:\n",
    "        i = random.randint(0, vocab_size - 1)\n",
    "        j = random.randint(0, vocab_size - 1)\n",
    "        if i != j and (i, j) not in existing_set:\n",
    "            neg_edges.add((i, j))\n",
    "    return list(neg_edges)\n",
    "\n",
    "# --- Step 7: Training, Evaluation, and Saving ---\n",
    "input_dim = embeddings.size(1)\n",
    "hidden_dim = 256\n",
    "num_rels = len(rel_encoder.classes_)\n",
    "num_classes = num_rels + 1  # extra class for 'no-relation'\n",
    "\n",
    "encoder = RGAT(input_dim, hidden_dim, input_dim, num_rels)\n",
    "classifier = EdgeClassifier(input_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=1e-3)\n",
    "\n",
    "# Positive edges\n",
    "pos_src = edge_index[0]\n",
    "pos_dst = edge_index[1]\n",
    "pos_labels = edge_type\n",
    "\n",
    "# Track used pairs for negative sampling\n",
    "pos_pairs = set(zip(pos_src.tolist(), pos_dst.tolist()))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "split = int(0.8 * len(pos_labels))\n",
    "train_pos = (pos_src[:split], pos_dst[:split], pos_labels[:split])\n",
    "test_pos = (pos_src[split:], pos_dst[split:], pos_labels[split:])\n",
    "\n",
    "for epoch in range(100):\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    # Generate new negative edges\n",
    "    neg_pairs = generate_negative_edges(len(pos_labels), len(words), pos_pairs)\n",
    "    neg_src, neg_dst = zip(*neg_pairs)\n",
    "    neg_src, neg_dst = torch.tensor(neg_src), torch.tensor(neg_dst)\n",
    "    neg_labels = torch.full_like(neg_src, fill_value=num_rels)  # 'no-relation'\n",
    "\n",
    "    # Combine batches\n",
    "    train_src = torch.cat([train_pos[0], neg_src])\n",
    "    train_dst = torch.cat([train_pos[1], neg_dst])\n",
    "    train_labels = torch.cat([train_pos[2], neg_labels])\n",
    "\n",
    "    h = encoder(embeddings, edge_index, edge_type)\n",
    "    logits = classifier(h[train_src], h[train_dst])\n",
    "    loss = F.cross_entropy(logits, train_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc = (pred == train_labels).float().mean()\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Acc: {acc.item():.4f}\")\n",
    "        if epoch % 50 == 0:\n",
    "            evaluate(encoder, classifier, embeddings, edge_index, edge_type, test_pos, num_rels)\n",
    "\n",
    "# Save models\n",
    "torch.save(encoder.state_dict(), 'rgat_encoder.pt')\n",
    "torch.save(classifier.state_dict(), 'rgat_classifier.pt')\n",
    "print(\"Models saved: 'rgat_encoder.pt' and 'rgat_classifier.pt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FN4.Pytorch",
   "language": "python",
   "name": "fn4.pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
