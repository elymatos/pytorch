{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600b4ae6-7005-4e93-bf8b-495c7b8c0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model weights from rgat_model.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123309/3758014111.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('rgat_model.pt', map_location=device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 215\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m    214\u001b[0m new_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis work proposes a novel GNN method with attention.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 215\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_and_insert_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgnn_paper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_node\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgnn_paper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m: results}, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    217\u001b[0m save_graph_state()\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 155\u001b[0m, in \u001b[0;36mpredict_and_insert_node\u001b[0;34m(text, node_name, top_k)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_name \u001b[38;5;129;01min\u001b[39;00m NEW_NODES:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NEW_NODES[node_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 155\u001b[0m out_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_global\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m norm_existing \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(out_embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    157\u001b[0m norm_new \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(new_embed, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m, in \u001b[0;36mRGATModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 106\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrgat1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    107\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    108\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrgat2(x, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 93\u001b[0m, in \u001b[0;36mRelationalGATLayer.forward\u001b[0;34m(self, x, edge_index, edge_type)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_type):\n\u001b[0;32m---> 93\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat(x, edge_index, edge_attr)\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fn4.pytorch/lib/python3.9/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üîÅ R-GAT Prototype with BERT + Edge Types\n",
    "# ============================================\n",
    "# Features:\n",
    "# - Loads graph from CSV file\n",
    "# - Encodes nodes using BERT\n",
    "# - Uses custom R-GAT layer with edge-type-aware attention\n",
    "# - Supports model saving and loading\n",
    "# - Relation types included in edge attributes and training logic\n",
    "# - Includes link prediction and dynamic graph update\n",
    "\n",
    "import os\n",
    "# üì¶ Install dependencies\n",
    "#!pip install transformers torch-geometric networkx pandas --quiet\n",
    "\n",
    "# ==============================\n",
    "# üîÅ Load Graph State If Available\n",
    "# ==============================\n",
    "if os.path.exists('graph_state.pt'):\n",
    "    print(\"üîÅ Loading saved graph state from disk...\")\n",
    "    saved = torch.load('graph_state.pt')\n",
    "    x = saved['x']\n",
    "    edge_index = saved['edge_index']\n",
    "    edge_type = saved['edge_type']\n",
    "    nodes = saved['nodes']\n",
    "    NEW_NODES = saved.get('new_nodes', {})\n",
    "else:\n",
    "    pass  # Placeholder to fix indentation error\n",
    "# ==============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# üì• Globals\n",
    "# ==============================\n",
    "NEW_NODES = {}\n",
    "\n",
    "# ==============================\n",
    "# üßæ Load Graph from CSV\n",
    "# ==============================\n",
    "edges_df = pd.read_csv(\"graph_edges.csv\")\n",
    "\n",
    "# Encode edge types\n",
    "edge_encoder = LabelEncoder()\n",
    "edges_df['edge_type_id'] = edge_encoder.fit_transform(edges_df['edge_type'])\n",
    "\n",
    "# Map node IDs to indices\n",
    "nodes = pd.Index(edges_df['source'].tolist() + edges_df['target'].tolist()).unique()\n",
    "node_id_map = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "# Build edge_index and edge_type tensors\n",
    "source = edges_df['source'].map(node_id_map).tolist()\n",
    "target = edges_df['target'].map(node_id_map).tolist()\n",
    "edge_index = torch.tensor([source, target], dtype=torch.long).to(device)\n",
    "edge_type = torch.tensor(edges_df['edge_type_id'], dtype=torch.long).to(device)\n",
    "\n",
    "# ==============================\n",
    "# üß† Encode Node Texts with BERT\n",
    "# ==============================\n",
    "node_texts = pd.read_csv(\"node_texts.csv\")\n",
    "node_texts = node_texts.set_index(\"node_id\").reindex(nodes).fillna(\"\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size].tolist()\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "        outputs = bert(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :])\n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "x = encode_texts(node_texts['text']).to(device)\n",
    "\n",
    "# ==============================\n",
    "# üì¶ PyG Data Object\n",
    "# ==============================\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data.edge_type = edge_type\n",
    "\n",
    "# ==============================\n",
    "# üß† Define R-GAT Layer\n",
    "# ==============================\n",
    "class RelationalGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_relations, heads=4):\n",
    "        super().__init__()\n",
    "        self.rel_embeddings = nn.Embedding(num_relations, in_dim)\n",
    "        self.gat = GATConv(in_dim, out_dim, heads=heads, concat=False, dropout=0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        edge_attr = self.rel_embeddings(edge_type)\n",
    "        return self.gat(x, edge_index, edge_attr)\n",
    "\n",
    "# ==============================\n",
    "# üèóÔ∏è Define Full Model\n",
    "# ==============================\n",
    "class RGATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_relations):\n",
    "        super().__init__()\n",
    "        self.rgat1 = RelationalGATLayer(in_dim, hidden_dim, num_relations)\n",
    "        self.rgat2 = RelationalGATLayer(hidden_dim, out_dim, num_relations)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.rgat1(data.x, data.edge_index, data.edge_type))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.rgat2(x, data.edge_index, data.edge_type)\n",
    "        return x\n",
    "\n",
    "# ==============================\n",
    "# ‚öôÔ∏è Setup Model for Inference\n",
    "# ==============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGATModel(\n",
    "    in_dim=x_global.size(1),\n",
    "    hidden_dim=128,\n",
    "    out_dim=3,\n",
    "    num_relations=len(edge_encoder.classes_)\n",
    ").to(device)\n",
    "data_global = data_global.to(device)\n",
    "\n",
    "# Load model if saved\n",
    "if os.path.exists('rgat_model.pt'):\n",
    "    print(\"üì¶ Loading model weights from rgat_model.pt...\")\n",
    "    checkpoint = torch.load('rgat_model.pt', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: No saved model found. Using untrained model.\")\n",
    "\n",
    "# ==============================\n",
    "# üîó Dynamic Insertion + Prediction\n",
    "# ==============================\n",
    "# Globals to track modifiable variables\n",
    "# Ensure they are properly mutable (not reassigned in function scope)\n",
    "x_global = x\n",
    "nodes_global = list(nodes)\n",
    "data_global = data\n",
    "\n",
    "# ==============================\n",
    "@torch.no_grad()\n",
    "def predict_and_insert_node(text, node_name=None, top_k=5):\n",
    "    global x_global, nodes_global, data_global\n",
    "    model.eval()\n",
    "    inputs = tokenizer([text], return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "    new_embed = bert(**inputs).last_hidden_state[:, 0, :].to(device)\n",
    "\n",
    "    if node_name is None:\n",
    "        node_name = f\"new_node_{len(NEW_NODES)}\"\n",
    "\n",
    "    if node_name in NEW_NODES:\n",
    "        return NEW_NODES[node_name]['results']\n",
    "\n",
    "    out_embeddings = model(data_global)\n",
    "    norm_existing = F.normalize(out_embeddings, dim=1)\n",
    "    norm_new = F.normalize(new_embed, dim=1)\n",
    "\n",
    "    sims = torch.matmul(norm_existing, norm_new.T).squeeze()\n",
    "    topk = torch.topk(sims, top_k)\n",
    "    top_indices = topk.indices.tolist()\n",
    "    top_scores = topk.values.tolist()\n",
    "    linked_nodes = [nodes[i] for i in top_indices]\n",
    "\n",
    "    # Update graph (in memory only)\n",
    "    x_global = torch.cat([x_global, new_embed], dim=0)\n",
    "    new_index = x_global.shape[0] - 1\n",
    "    new_edges = torch.tensor([[new_index] * top_k, top_indices], dtype=torch.long).to(device)\n",
    "    data_global.edge_index = torch.cat([data_global.edge_index, new_edges], dim=1)\n",
    "    data_global.edge_type = torch.cat([data_global.edge_type, torch.zeros(top_k, dtype=torch.long, device=device)])\n",
    "    data_global.x = x_global\n",
    "    nodes_global = nodes_global + [node_name]\n",
    "\n",
    "    # Save prediction\n",
    "    result = [{\"node\": n, \"score\": s} for n, s in zip(linked_nodes, top_scores)]\n",
    "    NEW_NODES[node_name] = {\"text\": text, \"results\": result}\n",
    "    return result\n",
    "\n",
    "# ==============================\n",
    "# üíæ Export Graph to CSV for External Tools\n",
    "# ==============================\n",
    "def export_graph_to_csv():\n",
    "    edge_idx_np = data_global.edge_index.cpu().numpy()\n",
    "    edge_types_np = data_global.edge_type.cpu().numpy()\n",
    "    edge_type_labels = edge_encoder.inverse_transform(edge_types_np[:len(edge_types_np)])\n",
    "    rows = []\n",
    "    for i in range(edge_idx_np.shape[1]):\n",
    "        src = nodes_global[edge_idx_np[0, i]]\n",
    "        tgt = nodes_global[edge_idx_np[1, i]]\n",
    "        rel = edge_type_labels[i] if i < len(edge_type_labels) else 'unknown'\n",
    "        rows.append({'source': src, 'target': tgt, 'edge_type': rel})\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"exported_graph.csv\", index=False)\n",
    "    print(\"‚úÖ Exported full graph to exported_graph.csv\")\n",
    "\n",
    "# ==============================\n",
    "# üíæ Persist Graph to Disk\n",
    "# ==============================\n",
    "def save_graph_state():\n",
    "    export_graph_to_csv()\n",
    "    torch.save({\n",
    "        'x': x_global,\n",
    "        'edge_index': data_global.edge_index,\n",
    "        'edge_type': data_global.edge_type,\n",
    "        'nodes': nodes_global,\n",
    "        'new_nodes': NEW_NODES\n",
    "    }, 'graph_state.pt')\n",
    "    print(\"‚úÖ Graph state saved to graph_state.pt\")\n",
    "\n",
    "# ==============================\n",
    "# üì§ Serve Prediction as JSON\n",
    "# ==============================\n",
    "import json\n",
    "new_text = \"This work proposes a novel GNN method with attention.\"\n",
    "results = predict_and_insert_node(new_text, node_name=\"gnn_paper\")\n",
    "print(json.dumps({\"new_node\": \"gnn_paper\", \"links\": results}, indent=2))\n",
    "save_graph_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234e569-d0d4-4236-859a-11049ed82e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FN4.PyTorch",
   "language": "python",
   "name": "fn4.pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
