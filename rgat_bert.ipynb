{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600b4ae6-7005-4e93-bf8b-495c7b8c0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model weights from rgat_model.pt...\n",
      "{\n",
      "  \"new_node\": \"gnn_paper\",\n",
      "  \"links\": [\n",
      "    {\n",
      "      \"node\": \"doc2\",\n",
      "      \"score\": -0.051176540553569794\n",
      "    },\n",
      "    {\n",
      "      \"node\": \"doc4\",\n",
      "      \"score\": -0.09231094270944595\n",
      "    },\n",
      "    {\n",
      "      \"node\": \"doc1\",\n",
      "      \"score\": -0.09750363230705261\n",
      "    },\n",
      "    {\n",
      "      \"node\": \"doc3\",\n",
      "      \"score\": -0.10710319876670837\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "‚úÖ Exported full graph to exported_graph.csv\n",
      "‚úÖ Graph state saved to graph_state.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123309/3459406783.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('rgat_model.pt', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üîÅ R-GAT Prototype with BERT + Edge Types\n",
    "# ============================================\n",
    "# Features:\n",
    "# - Loads graph from CSV file\n",
    "# - Encodes nodes using BERT\n",
    "# - Uses custom R-GAT layer with edge-type-aware attention\n",
    "# - Supports model saving and loading\n",
    "# - Relation types included in edge attributes and training logic\n",
    "# - Includes link prediction and dynamic graph update\n",
    "\n",
    "import os\n",
    "# üì¶ Install dependencies\n",
    "#!pip install transformers torch-geometric networkx pandas --quiet\n",
    "\n",
    "# ==============================\n",
    "# üîÅ Load Graph State If Available\n",
    "# ==============================\n",
    "if os.path.exists('graph_state.pt'):\n",
    "    print(\"üîÅ Loading saved graph state from disk...\")\n",
    "    saved = torch.load('graph_state.pt')\n",
    "    x = saved['x']\n",
    "    edge_index = saved['edge_index']\n",
    "    edge_type = saved['edge_type']\n",
    "    nodes = saved['nodes']\n",
    "    NEW_NODES = saved.get('new_nodes', {})\n",
    "else:\n",
    "    pass  # Placeholder to fix indentation error\n",
    "# ==============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# üì• Globals\n",
    "# ==============================\n",
    "NEW_NODES = {}\n",
    "\n",
    "# ==============================\n",
    "# üßæ Load Graph from CSV\n",
    "# ==============================\n",
    "edges_df = pd.read_csv(\"graph_edges.csv\")\n",
    "\n",
    "# Encode edge types\n",
    "edge_encoder = LabelEncoder()\n",
    "edges_df['edge_type_id'] = edge_encoder.fit_transform(edges_df['edge_type'])\n",
    "\n",
    "# Map node IDs to indices\n",
    "nodes = pd.Index(edges_df['source'].tolist() + edges_df['target'].tolist()).unique()\n",
    "node_id_map = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "# Build edge_index and edge_type tensors\n",
    "source = edges_df['source'].map(node_id_map).tolist()\n",
    "target = edges_df['target'].map(node_id_map).tolist()\n",
    "edge_index = torch.tensor([source, target], dtype=torch.long).to(device)\n",
    "edge_type = torch.tensor(edges_df['edge_type_id'], dtype=torch.long).to(device)\n",
    "\n",
    "# ==============================\n",
    "# üîÑ Projection from BERT to GNN space\n",
    "bert_proj = nn.Linear(768, 128).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# ==============================\n",
    "# üß† Encode Node Texts with BERT\n",
    "# ==============================\n",
    "node_texts = pd.read_csv(\"node_texts.csv\")\n",
    "node_texts = node_texts.set_index(\"node_id\").reindex(nodes).fillna(\"\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size].tolist()\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "        outputs = bert(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :])\n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "x = encode_texts(node_texts['text']).to(device)\n",
    "\n",
    "# ==============================\n",
    "# üì¶ PyG Data Object\n",
    "# ==============================\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data.edge_type = edge_type\n",
    "\n",
    "# ==============================\n",
    "# üß† Define R-GAT Layer\n",
    "# ==============================\n",
    "class RelationalGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_relations, heads=4):\n",
    "        super().__init__()\n",
    "        self.rel_embeddings = nn.Embedding(num_relations, in_dim)\n",
    "        self.gat = GATConv(in_dim, out_dim, heads=heads, concat=False, dropout=0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        edge_attr = self.rel_embeddings(edge_type)\n",
    "        return self.gat(x, edge_index, edge_attr)\n",
    "\n",
    "# ==============================\n",
    "# üèóÔ∏è Define Full Model\n",
    "# ==============================\n",
    "class RGATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_relations):\n",
    "        super().__init__()\n",
    "        self.rgat1 = RelationalGATLayer(in_dim, hidden_dim, num_relations)\n",
    "        self.rgat2 = RelationalGATLayer(hidden_dim, out_dim, num_relations)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.rgat1(data.x, data.edge_index, data.edge_type))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.rgat2(x, data.edge_index, data.edge_type)\n",
    "        return x\n",
    "\n",
    "    def embed_nodes(self, data):\n",
    "        with torch.no_grad():\n",
    "            x = F.relu(self.rgat1(data.x, data.edge_index, data.edge_type))\n",
    "        return x\n",
    "\n",
    "# ==============================\n",
    "# ‚öôÔ∏è Setup Model for Inference\n",
    "# ==============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGATModel(\n",
    "    in_dim=x_global.size(1),\n",
    "    hidden_dim=128,\n",
    "    out_dim=3,\n",
    "    num_relations=len(edge_encoder.classes_)\n",
    ").to(device)\n",
    "data_global = data_global.to(device)\n",
    "\n",
    "# Load model if saved\n",
    "if os.path.exists('rgat_model.pt'):\n",
    "    print(\"üì¶ Loading model weights from rgat_model.pt...\")\n",
    "    checkpoint = torch.load('rgat_model.pt', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if 'bert_proj_state_dict' in checkpoint:\n",
    "        bert_proj.load_state_dict(checkpoint['bert_proj_state_dict'])\n",
    "    model.eval()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: No saved model found. Using untrained model.\")\n",
    "\n",
    "# ==============================\n",
    "# üîó Dynamic Insertion + Prediction\n",
    "# ==============================\n",
    "# Globals to track modifiable variables\n",
    "# Ensure they are properly mutable (not reassigned in function scope)\n",
    "x_global = x\n",
    "nodes_global = list(nodes)\n",
    "data_global = data\n",
    "\n",
    "# ==============================\n",
    "@torch.no_grad()\n",
    "def predict_and_insert_node(text, node_name=None, top_k=5):\n",
    "    global x_global, nodes_global, data_global\n",
    "    model.eval()\n",
    "    inputs = tokenizer([text], return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "    new_embed = bert_proj(bert(**inputs).last_hidden_state[:, 0, :].to(device))\n",
    "\n",
    "    if node_name is None:\n",
    "        node_name = f\"new_node_{len(NEW_NODES)}\"\n",
    "\n",
    "    if node_name in NEW_NODES:\n",
    "        return NEW_NODES[node_name]['results']\n",
    "\n",
    "    out_embeddings = model.embed_nodes(data_global)\n",
    "    norm_existing = F.normalize(out_embeddings, dim=1)\n",
    "    norm_new = F.normalize(new_embed, dim=1)\n",
    "\n",
    "    sims = torch.matmul(norm_existing, norm_new.T).squeeze()\n",
    "    top_k_safe = min(top_k, sims.shape[0])\n",
    "    topk = torch.topk(sims, top_k_safe)\n",
    "    top_indices = topk.indices.tolist()\n",
    "    top_scores = topk.values.tolist()\n",
    "    linked_nodes = [nodes[i] for i in top_indices]\n",
    "\n",
    "    # Update graph (in memory only)\n",
    "    new_embed_resized = torch.zeros((1, x_global.size(1)), device=device)\n",
    "    new_embed_resized[:, :min(128, x_global.size(1))] = new_embed[:, :min(128, x_global.size(1))]\n",
    "    x_global = torch.cat([x_global, new_embed_resized], dim=0)\n",
    "    new_index = x_global.shape[0] - 1\n",
    "    top_indices_tensor = torch.tensor(top_indices, dtype=torch.long, device=device)\n",
    "    new_edges = torch.stack([\n",
    "        torch.full((top_k_safe,), new_index, dtype=torch.long, device=device),\n",
    "        top_indices_tensor\n",
    "    ], dim=0)\n",
    "    data_global.edge_index = torch.cat([data_global.edge_index, new_edges], dim=1)\n",
    "    data_global.edge_type = torch.cat([data_global.edge_type, torch.zeros(top_k, dtype=torch.long, device=device)])\n",
    "    data_global.x = x_global\n",
    "    nodes_global = nodes_global + [node_name]\n",
    "\n",
    "    # Save prediction\n",
    "    result = [{\"node\": n, \"score\": s} for n, s in zip(linked_nodes, top_scores)]\n",
    "    NEW_NODES[node_name] = {\"text\": text, \"results\": result}\n",
    "    return result\n",
    "\n",
    "# ==============================\n",
    "# üíæ Export Graph to CSV for External Tools\n",
    "# ==============================\n",
    "def export_graph_to_csv():\n",
    "    edge_idx_np = data_global.edge_index.cpu().numpy()\n",
    "    edge_types_np = data_global.edge_type.cpu().numpy()\n",
    "    edge_type_labels = edge_encoder.inverse_transform(edge_types_np[:len(edge_types_np)])\n",
    "    rows = []\n",
    "    for i in range(edge_idx_np.shape[1]):\n",
    "        src = nodes_global[edge_idx_np[0, i]]\n",
    "        tgt = nodes_global[edge_idx_np[1, i]]\n",
    "        rel = edge_type_labels[i] if i < len(edge_type_labels) else 'unknown'\n",
    "        rows.append({'source': src, 'target': tgt, 'edge_type': rel})\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"exported_graph.csv\", index=False)\n",
    "    print(\"‚úÖ Exported full graph to exported_graph.csv\")\n",
    "\n",
    "# ==============================\n",
    "# üíæ Persist Graph to Disk\n",
    "# ==============================\n",
    "def save_graph_state():\n",
    "    export_graph_to_csv()\n",
    "    torch.save({\n",
    "        'bert_proj_state_dict': bert_proj.state_dict(),\n",
    "        'x': x_global,\n",
    "        'edge_index': data_global.edge_index,\n",
    "        'edge_type': data_global.edge_type,\n",
    "        'nodes': nodes_global,\n",
    "        'new_nodes': NEW_NODES\n",
    "    }, 'graph_state.pt')\n",
    "    print(\"‚úÖ Graph state saved to graph_state.pt\")\n",
    "\n",
    "# ==============================\n",
    "# üì§ Serve Prediction as JSON\n",
    "# ==============================\n",
    "import json\n",
    "new_text = \"This work proposes a novel GNN method with attention.\"\n",
    "results = predict_and_insert_node(new_text, node_name=\"gnn_paper\")\n",
    "print(json.dumps({\"new_node\": \"gnn_paper\", \"links\": results}, indent=2))\n",
    "save_graph_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234e569-d0d4-4236-859a-11049ed82e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FN4.PyTorch",
   "language": "python",
   "name": "fn4.pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
