{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa81f1f-1fc4-4cc4-bab7-797c5031da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# FULL ENHANCED HTPC + HTM MODEL - Using language\n",
    "#  Includes L3, plotting, sparse L1 visualization\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# === Minicolumn Encoder ===\n",
    "class MinicolumnEncoder(nn.Module):\n",
    "    def __init__(self, n_columns, cells_per_column):\n",
    "        super().__init__()\n",
    "        self.n_columns = n_columns\n",
    "        self.cells_per_column = cells_per_column\n",
    "        self.total_cells = n_columns * cells_per_column\n",
    "        self.recurrent_weights = nn.Parameter(torch.zeros(self.total_cells, self.total_cells))\n",
    "\n",
    "    def activate(self, input_vector, prev_state):\n",
    "        input_cells = input_vector.repeat_interleave(self.cells_per_column)\n",
    "        context_input = torch.matmul(self.recurrent_weights, prev_state)\n",
    "        combined = input_cells + context_input\n",
    "        combined = combined.view(self.n_columns, self.cells_per_column)\n",
    "        active_cells = torch.zeros_like(combined)\n",
    "        #winners = torch.argmax(combined, dim=1)\n",
    "        noise = 0.01 * torch.rand_like(combined)  # small randomness\n",
    "        combined += noise\n",
    "        winners = torch.argmax(combined, dim=1)\n",
    "        self.last_winners = winners.detach().clone()\n",
    "        active_cells[range(self.n_columns), winners] = 1.0\n",
    "        return active_cells.view(-1)\n",
    "\n",
    "    def learn(self, prev_state, current_state, lr=0.01):\n",
    "        dw = torch.ger(current_state, prev_state)\n",
    "        self.recurrent_weights.data += lr * dw\n",
    "\n",
    "# === HTPC Layer ===\n",
    "class HTPCLayer(nn.Module):\n",
    "    def __init__(self, size, next_size=None, prev_size=None):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.state = torch.zeros(size)\n",
    "        self.prediction = torch.zeros(size)\n",
    "        self.error = torch.zeros(size)\n",
    "        self.ff_weights = nn.Parameter(torch.randn(size, prev_size) * 0.1) if prev_size else None\n",
    "        self.fb_weights = nn.Parameter(torch.randn(size, next_size) * 0.1) if next_size else None\n",
    "\n",
    "    def forward(self, bottom_up=None, top_down=None):\n",
    "        ff_input = F.linear(bottom_up, self.ff_weights) if self.ff_weights is not None and bottom_up is not None else 0\n",
    "        fb_input = F.linear(top_down, self.fb_weights) if self.fb_weights is not None and top_down is not None else 0\n",
    "        #self.state = torch.tanh(ff_input + fb_input)\n",
    "        self.state = torch.relu(ff_input + fb_input)  # OR\n",
    "        #self.state = ff_input + fb_input  # Raw linear\n",
    "        self.prediction = fb_input\n",
    "        self.error = self.state - self.prediction\n",
    "        return self.state, self.error\n",
    "\n",
    "# === Full HTPC-HTM Model with L3 and visualization ===\n",
    "class HTPCModelHTM(nn.Module):\n",
    "    def __init__(self, n_columns=10, cells_per_column=16, l2_size=10, l3_size=5):\n",
    "        super().__init__()\n",
    "        self.encoder = MinicolumnEncoder(n_columns, cells_per_column)\n",
    "        self.n_input = n_columns * cells_per_column\n",
    "        self.L2 = HTPCLayer(l2_size, prev_size=self.n_input, next_size=l3_size)\n",
    "        self.L3 = HTPCLayer(l3_size, prev_size=l2_size)\n",
    "        self.L1_fb = nn.Parameter(torch.randn(self.n_input, l2_size) * 0.1)\n",
    "\n",
    "        self.prev_L1_state = torch.zeros(self.n_input)\n",
    "        self.current_input_column = torch.zeros(n_columns)\n",
    "\n",
    "        # Logs\n",
    "        self.log_L1_acts = []\n",
    "        self.log_L1_error = []\n",
    "        self.log_L2_error = []\n",
    "\n",
    "    def forward(self, column_input):\n",
    "        self.current_input_column = column_input.clone()\n",
    "\n",
    "        # L1 Activation\n",
    "        L1_state = self.encoder.activate(column_input, self.prev_L1_state)\n",
    "\n",
    "        # Feedforward\n",
    "        L2_state, _ = self.L2.forward(bottom_up=L1_state)\n",
    "        L3_state, _ = self.L3.forward(bottom_up=self.L2.state)\n",
    "\n",
    "        # Feedback\n",
    "        self.L2.forward(top_down=L3_state)\n",
    "        #L1_pred = F.linear(self.L2.state, self.L1_fb)\n",
    "        self.L1_pred_bias = nn.Parameter(torch.zeros(self.n_input))\n",
    "        L1_pred = F.linear(self.L2.state, self.L1_fb) + self.L1_pred_bias\n",
    "        L1_error = L1_state - L1_pred\n",
    "\n",
    "        # Logs\n",
    "        self.log_L1_acts.append(L1_state.detach().numpy())\n",
    "        self.log_L1_error.append(torch.sum(L1_error ** 2).item())\n",
    "        self.log_L2_error.append(torch.sum(self.L2.error ** 2).item())\n",
    "\n",
    "        self.prev_L1_state = L1_state.clone()\n",
    "        #print(\"FF dW (L2):\", torch.norm(torch.ger(self.L2.error, self.prev_L1_state)).item())\n",
    "        #print(\"FB dW (L1):\", torch.norm(torch.ger(-self.prev_L1_state, self.L2.state)).item())\n",
    "        return {\"L1_error\": L1_error}\n",
    "\n",
    "    def learn(self, lr=0.01):\n",
    "        with torch.no_grad():\n",
    "            pred = F.linear(self.L2.state, self.L1_fb)\n",
    "            error = self.prev_L1_state - pred\n",
    "            self.L1_fb += lr * torch.ger(error, self.L2.state)\n",
    "\n",
    "            self.L2.ff_weights += lr * torch.ger(self.L2.error, self.prev_L1_state)\n",
    "            self.L3.ff_weights += lr * torch.ger(self.L3.error, self.L2.state)\n",
    "\n",
    "            new_L1_state = self.encoder.activate(self.current_input_column, self.prev_L1_state)\n",
    "            self.encoder.learn(self.prev_L1_state, new_L1_state, lr=lr)\n",
    "\n",
    "\n",
    "    def reset_logs(self):\n",
    "        self.log_L1_acts.clear()\n",
    "        self.log_L1_error.clear()\n",
    "        self.log_L2_error.clear()\n",
    "\n",
    "    def plot_results(self):\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "        axs[0].imshow(np.array(self.log_L1_acts).T, aspect='auto', cmap='Greys')\n",
    "        axs[0].set_title(\"L1 Sparse Activations (minicolumn cells)\")\n",
    "        axs[0].set_ylabel(\"Cell index\")\n",
    "\n",
    "        axs[1].plot(self.log_L1_error, label='L1 Error', color='magenta')\n",
    "        axs[1].set_title(\"L1 Prediction Error\")\n",
    "        axs[1].set_ylabel(\"MSE\")\n",
    "\n",
    "        axs[2].plot(self.log_L2_error, label='L2 Error', color='orange')\n",
    "        axs[2].set_title(\"L2 Prediction Error\")\n",
    "        axs[2].set_ylabel(\"MSE\")\n",
    "        axs[2].set_xlabel(\"Time step\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a060c1c3-6701-4a87-92bb-f3e758e2b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word: ['sat']\n"
     ]
    }
   ],
   "source": [
    "sequences = [\n",
    "    [\"the\", \"cat\", \"sat\"],\n",
    "    [\"the\", \"dog\", \"ran\"],\n",
    "    [\"the\", \"cat\", \"ran\"],\n",
    "    [\"the\", \"dog\", \"sat\"]\n",
    "]\n",
    "\n",
    "# Build a word-to-column mapping\n",
    "words = sorted(set(word for seq in sequences for word in seq))\n",
    "word_to_column = {word: i for i, word in enumerate(words)}  # e.g., {\"the\": 0, \"cat\": 1, ...}\n",
    "\n",
    "def encode_word(word, n_columns):\n",
    "    vec = torch.zeros(n_columns)\n",
    "    if word in word_to_column:\n",
    "        vec[word_to_column[word]] = 1.0\n",
    "    return vec\n",
    "\n",
    "# Setup\n",
    "n_columns = len(word_to_column)\n",
    "cells_per_column = 16\n",
    "model = HTPCModelHTM(n_columns=n_columns, cells_per_column=cells_per_column, l2_size=10, l3_size=5)\n",
    "\n",
    "\n",
    "# Build overlapping sequences\n",
    "def make_column_input(indices):\n",
    "    vec = torch.zeros(n_columns)\n",
    "    vec[indices] = 1.0\n",
    "    return vec\n",
    "\n",
    "# === TRAINING ===\n",
    "model.reset_logs()\n",
    "\n",
    "for epoch in range(30):\n",
    "    for seq in sequences:\n",
    "        model.prev_L1_state = torch.zeros_like(model.prev_L1_state)\n",
    "\n",
    "        for i in range(len(seq)):\n",
    "            word = seq[i]\n",
    "            column_input = encode_word(word, n_columns)\n",
    "\n",
    "            model.forward(column_input)\n",
    "\n",
    "            if i > 0:\n",
    "                model.learn(lr=0.01)\n",
    "\n",
    "# === TESTING ===\n",
    "model.prev_L1_state = torch.zeros_like(model.prev_L1_state)\n",
    "\n",
    "test_input = [\"the\", \"cat\"]  # Expect \"sat\" or \"ran\" depending on training\n",
    "for word in test_input:\n",
    "    model.forward(encode_word(word, n_columns))\n",
    "\n",
    "# Show top predicted words\n",
    "L1_pred = F.linear(model.L2.state, model.L1_fb)\n",
    "\n",
    "# Get top predicted cell indices (across all 160 cells)\n",
    "top_indices = torch.topk(L1_pred, k=10).indices.tolist()\n",
    "\n",
    "# Convert to column indices\n",
    "predicted_column_indices = [idx // model.encoder.cells_per_column for idx in top_indices]\n",
    "\n",
    "# Map back to words\n",
    "predicted_words = [\n",
    "    word for word, col_idx in word_to_column.items()\n",
    "    if col_idx in predicted_column_indices\n",
    "]\n",
    "\n",
    "print(\"Predicted next word:\", predicted_words)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043a63f-4e87-4142-8316-4de65465bea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FN4.Pytorch",
   "language": "python",
   "name": "fn4.pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
