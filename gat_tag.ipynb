{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================\n",
    "# üì¶ Install Libraries\n",
    "# =============================\n",
    "!pip install torch torchvision torchaudio --quiet\n",
    "!pip install torch-geometric --quiet\n",
    "!pip install transformers --quiet\n",
    "\n",
    "# =============================\n",
    "# üìö Imports\n",
    "# =============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATConv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================\n",
    "# üì• Load Cora Dataset\n",
    "# =============================\n",
    "dataset = Planetoid(root='data/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# =============================\n",
    "# üß† Generate BERT Texts (Simulated Abstracts)\n",
    "# =============================\n",
    "node_ids = [f\"Paper about topic {int(label)}\" for label in data.y.tolist()]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert.eval()\n",
    "\n",
    "def embed_texts(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(**inputs)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings)\n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "x = embed_texts(node_ids)\n",
    "x = torch.tensor(normalize(x), dtype=torch.float)\n",
    "data.x = x  # Replace node features\n",
    "\n",
    "# =============================\n",
    "# üß† Define GAT Model\n",
    "# =============================\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# =============================\n",
    "# üèãÔ∏è Train Model\n",
    "# =============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(in_channels=x.shape[1], hidden_channels=32, out_channels=7).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# =============================\n",
    "# üìà Plot Loss\n",
    "# =============================\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"CrossEntropy Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# ‚úÖ Evaluate\n",
    "# =============================\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int((pred[data.test_mask] == data.y[data.test_mask]).sum())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ],
   "id": "87d61620a404a2b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
